"""AI Grading Engine using Gemini 3 Pro with Thinking Mode

This module handles the core grading logic by sending student images and curriculum
context to Gemini 3 Pro and parsing the structured JSON response.
"""
import json
from pathlib import Path
from typing import Dict, List
import sys

from google import genai

sys.path.append(str(Path(__file__).parent.parent))
from config import GOOGLE_API_KEY, GEMINI_MODEL, THINKING_LEVEL, CURRICULUM_FILE, MAX_SCORE
from utils.logger import setup_logger

logger = setup_logger("grader")

class PhysicsGrader:
    """AI-powered physics grader using Gemini 3 Pro"""
    
    def __init__(self):
        """Initialize the Gemini client and upload curriculum PDFs"""
        logger.info("Initializing PhysicsGrader")
        
        # Initialize Gemini client
        self.client = genai.Client(api_key=GOOGLE_API_KEY)
        logger.info(f"Using model: {GEMINI_MODEL}")
        
        # Upload curriculum PDFs to Gemini (persistent files)
        self.curriculum_files = self._upload_curriculum_pdfs()
        logger.info("Curriculum PDFs uploaded successfully")
    
    def _upload_curriculum_pdfs(self) -> Dict:
        """Upload curriculum PDFs to Gemini as persistent files"""
        from .pdf_finder import find_curriculum_pdfs
        
        # Find PDFs by file size (avoids Arabic filename encoding issues)
        pdf_paths = find_curriculum_pdfs()
        
        if not pdf_paths:
            raise Exception("Curriculum PDFs not found!")
        
        uploaded_files = {}
        
        for category, pdf_path in pdf_paths.items():
            if not pdf_path.exists():
                logger.warning(f"PDF not found: {pdf_path}")
                continue
                
            logger.info(f"Uploading {category} ({pdf_path.stat().st_size // 1_000_000}MB)...")
            try:
                # Upload PDF file using path
                file_obj = self.client.files.upload(file=pdf_path)
                uploaded_files[category] = file_obj
                logger.info(f"โ {category} uploaded successfully")
            except Exception as e:
                logger.error(f"Failed to upload {category}: {e}")

        if not uploaded_files:
            raise Exception("No curriculum PDFs could be uploaded!")
            
        return uploaded_files
    
    def _build_system_prompt(self, max_score: int = 10, total_questions: int = None) -> str:
        """Build the system prompt for grading with configurable max score
        
        Args:
            max_score: Maximum score for this question
            total_questions: Total number of questions in midterm (for validation)
        """
        
        # Add question detection instructions for midterm mode
        question_detection_note = ""
        if total_questions:
            question_detection_note = f"""
## ๐ข ุชุญุฏูุฏ ุฑูู ุงูุณุคุงู ุงูุฑุฆูุณู (ููู ุฌุฏุงู!):

**โ๏ธ ุชุญุฐูุฑ ููู: ูุฑูู ุจูู ุงูุฃุณุฆูุฉ ุงูุฑุฆูุณูุฉ ูุงูุฃุณุฆูุฉ ุงููุฑุนูุฉ!**

ูุฐุง ุงูุงูุชุญุงู ูุญุชูู ุนูู {total_questions} ุฃุณุฆูุฉ ุฑุฆูุณูุฉ ููุท (Q1, Q2, Q3, Q4 ุฃู ุณ1ุ ุณ2ุ ุณ3ุ ุณ4).

### ููู ุชุญุฏุฏ ุงูุณุคุงู ุงูุฑุฆูุณู:
ุงุจุญุซ ุนู ุนูุงูุงุช ุงูุณุคุงู ุงูุฑุฆูุณู **ุตุฑุงุญุฉู**:
- "ุณ1" ุฃู "ุงูุณุคุงู ุงูุฃูู" ุฃู "Q1" โ ุณุคุงู ุฑุฆูุณู 1
- "ุณ2" ุฃู "ุงูุณุคุงู ุงูุซุงูู" ุฃู "Q2" โ ุณุคุงู ุฑุฆูุณู 2
- ูููุฐุง...

### โ๏ธ ูุง ุชุฎูุท ุจูู ุงูุฃุณุฆูุฉ ุงููุฑุนูุฉ ูุงูุฃุณุฆูุฉ ุงูุฑุฆูุณูุฉ!
ุฅุฐุง ุฑุฃูุช ุฃุฑูุงูุงู ูุซู "1-"ุ "2-"ุ "3-"ุ "ุฃ)"ุ "ุจ)" ุฏุงุฎู ุงูุฅุฌุงุจุฉ:
- ูุฐู **ุฃุณุฆูุฉ ูุฑุนูุฉ** ุถูู ุณุคุงู ุฑุฆูุณู ูุงุญุฏ
- **ูุง ุชุนุชุจุฑูุง** ุฃุณุฆูุฉ ุฑุฆูุณูุฉ ูููุตูุฉ!
- ุฅุฐุง ูู ูุฐูุฑ ุงูุทุงูุจ ุฑูู ุงูุณุคุงู ุงูุฑุฆูุณู ุตุฑุงุญุฉูุ ุฃุฑุฌุน [1] ูุงูุชุฑุงุถู

### ูุซุงู:
- ุงูุทุงูุจ ูุชุจ: "1- ... 2- ... 3- ..." โ ูุฐู ุฅุฌุงุจุงุช ุนูู ุฃุณุฆูุฉ ูุฑุนูุฉ ุถูู ุณุคุงู ุฑุฆูุณู ูุงุญุฏ
- ุฃุฑุฌุน: [1] (ุณุคุงู ุฑุฆูุณู ูุงุญุฏ ููุท)
- **ูุง ุชุฑุฌุน** [1,2,3] ูุฃู ูุฐู ุณุชุนูู 3 ุฃุณุฆูุฉ ุฑุฆูุณูุฉ!

**ุฃุฑูุงู ุงูุฃุณุฆูุฉ ุงูุตุงูุญุฉ**: 1 ุฅูู {total_questions} ููุท
"""
        
        prompt = f"""ุฃูุช "ุงููุนูู" (Al-Muallim)ุ ููุตุญุญ ููุฒูุงุก ูุชููู ูุนุงุฏู.

## ๐ฏ ููุณูุฉ ุงูุชุตุญูุญ: ุงูููู ุฃูู ูู ุงูุญูุธ!

**ูุงุนุฏุฉ ุฐูุจูุฉ**: ูุง ุชูุงุฑู ุงููุต ุญุฑููุงู! ูููู ุจูุงุกู ุนูู **ููู ุงูุทุงูุจ ููููููู**.

โ ุฅุฐุง ุดุฑุญ ุงูุทุงูุจ ุงูููุฑุฉ ุจุดูู ุตุญูุญ **ุจูููุงุชู ุงูุฎุงุตุฉ** โ ุตุญูุญ!
โ ุฅุฐุง ุงุณุชุฎุฏู ูุตุทูุญุงุช ูุฎุชููุฉ ููู ุงููุนูู ุตุญูุญ โ ุตุญูุญ!
โ ุฅุฐุง ุงูุฅุฌุงุจุฉ ุชุฏู ุนูู ููู ุงูููููู ุงูุนููู โ ุตุญูุญ!
โ ููุท ุฅุฐุง ูุงู ุงูููููู ุฃู ุงูููุทู ุฎุงุทุฆ โ ุฎุทุฃ!
{question_detection_note}
## ุงููููุฌ ุงูุฏุฑุงุณู (ูููุฑุฌุนูุฉ ููุท):
ูููุงุช PDF ุงููุฑููุฉ ุชุญุชูู ุนูู ุงูููุงููู ุงูุตุญูุญุฉ. ุงุณุชุฎุฏููุง ูููู ูุง ูุฌุจ ุฃู ูุนุฑูู ุงูุทุงูุจุ ููู **ูุง ุชุชููุน ุฃู ููุณุฎ ุงูุทุงูุจ ุงููุต ุญุฑููุงู**.

## ๐ ูุธุงู ุงูููุงุท (ุงูุฏุฑุฌุฉ ุงููุตูู: {max_score}):

### ุชุญุฏูุฏ ุนุฏุฏ ุงูุฃุณุฆูุฉ ุงููุฑุนูุฉ:
1. ุงูุธุฑ ุฅูู ูุฑูุฉ ุงูุณุคุงู ูุนุฏู ุงูุฃุณุฆูุฉ ุงููุฑุนูุฉ (T)
2. ูู ุณุคุงู ูุฑุนู = {max_score} รท T ููุงุท

### ูุนุงููุฑ ุงูุชูููู:
- **correct** โ: ุงูุทุงูุจ ูููู ุงูููููู ููุดุฑุญู ุจุดูู ุตุญูุญ (ุญุชู ูู ุจุฃุณููุจู ุงูุฎุงุต)
- **partial** โ๏ธ: ููู ุฌุฒุฆู - ุจุนุถ ุงูุฃููุงุฑ ุตุญูุญุฉ ูุจุนุถูุง ูุงูุต
- **mistake** โ: ุงูููููู ุฎุงุทุฆ ุฃู ุงูููุทู ุฎุงุทุฆ ุชูุงูุงู
- **unclear** โ: ูุง ูููู ูุฑุงุกุฉ ุงูุฎุท

### ุฃูุซูุฉ ุนูู ุงูุชูููู ุงูุตุญูุญ:

**ูุซุงู 1 - ูุฌุจ ุฃู ูููู correct:**
- ุงูุณุคุงู: ูุง ูู ุงูุนูุงูู ุงููุคุซุฑุฉ ูู ุงูููุงููุฉุ
- ุฅุฌุงุจุฉ ุงููููุฌ: "ุทูู ุงูุณููุ ูุณุงุญุฉ ุงูููุทุนุ ููุน ุงููุงุฏุฉุ ุฏุฑุฌุฉ ุงูุญุฑุงุฑุฉ"
- ุฅุฌุงุจุฉ ุงูุทุงูุจ: "ุงูููุงููุฉ ุชุนุชูุฏ ุนูู ุทูู ุงูููุตู ูุซุฎุงูุชู ูุงููุงุฏุฉ ุงููุตููุน ูููุง"
- โ **ุตุญูุญ!** ุงูุทุงูุจ ูููู ุงูููููู ุญุชู ูู ุงุณุชุฎุฏู ูููุงุช ูุฎุชููุฉ

**ูุซุงู 2 - ูุฌุจ ุฃู ูููู mistake:**
- ุงูุณุคุงู: ูู ุฃู ุฏุงุฆุฑุฉ ุชุชุญูู ุญุงูุฉ ุงูุฑูููุ
- ุงูุฅุฌุงุจุฉ ุงูุตุญูุญุฉ: ุฏุงุฆุฑุฉ RLC ุงููุชูุงููุฉ
- ุฅุฌุงุจุฉ ุงูุทุงูุจ: "ุฏุงุฆุฑุฉ ุงูุชูุงุฒู ููุท"
- โ **ุฎุทุฃ!** ุงูููููู ููุณู ุฎุงุทุฆ

**ูุซุงู 3 - ูุฌุจ ุฃู ูููู partial:**
- ุงูุณุคุงู: ุงุดุฑุญ ุธุงูุฑุฉ ุงูุฑููู ุงูููุฑุจุงุฆู
- ุฅุฌุงุจุฉ ุงูุทุงูุจ: "ูู ุงูุธุงูุฑุฉ ุงูุชู ุชุตู ูููุง ุงูุชูุงุฑ ูุฃุนูู ูููุฉ" (ุตุญูุญ ููู ูุงูุต)
- โ๏ธ **ุฌุฒุฆู!** ููู ุฌุฒุก ูู ุงูููููู ููู ูู ูุฐูุฑ ุงูุดุฑูุท

## ูุชุทูุจุงุช ุงูุฅุฎุฑุงุฌ (JSON ููุท):

{{
  "score": <ุฑูู ูู 0 ุฅูู {max_score}>,
  "question_numbers": [<ูุงุฆูุฉ ุฃุฑูุงู ุงูุฃุณุฆูุฉ ุงูุชู ูุฌูุจ ุนูููุง ุงูุทุงูุจุ ูุซุงู: [1] ุฃู [2,3]>],
  "feedback_ar": "<ููุงุญุธุงุช ูุฎุชุตุฑุฉ>",
  "annotations": [
    {{
      "text": "<ุงูุณุฎ ูุต ุฅุฌุงุจุฉ ุงูุทุงูุจ ุจุงูุถุจุท>",
      "label": "correct|mistake|partial|unclear"
    }}
  ]
}}

**ููุงุญุธุฉ ูููุฉ**: ุญูู "question_numbers" ุฅุฌุจุงุฑู! ุฅุฐุง ูู ุชุณุชุทุน ุชุญุฏูุฏ ุฑูู ุงูุณุคุงูุ ุฃุฑุฌุน [1] ูุงูุชุฑุงุถู.

## ุชุนูููุงุช annotations:

### 1. ุงูุณุฎ ูุต ุงูุฅุฌุงุจุฉ ุจุฏูุฉ:
- ุงูุณุฎ ูุง ูุชุจู ุงูุทุงูุจ **ุจุงูุถุจุท** ููุง ูุธูุฑ
- ูุฐุง ููุทุงุจูุฉ ุงููููุน ุนูู ุงูุตูุฑุฉุ ููุณ ููุชูููู

### 2. ูููู ุงูููููู ูููุณ ุงููููุงุช:
- **ูุง ุชูุงุฑู ุงููุต ุญุฑููุงู ุจุงููููุฌ**
- ุงุณุฃู: ูู ุงูุทุงูุจ ูููู ุงูููุฑุฉุ ูู ุงูููุทู ุตุญูุญุ

### 3. ูู ูุฑููุงู ูุน ุงูุฅุฌุงุจุงุช ุงูุฌูุฏุฉ:
- ุฅุฐุง ุงูุฌููุฑ ุตุญูุญ โ correct
- ุฅุฐุง ุฌุฒุก ุตุญูุญ ูุฌุฒุก ูุงูุต โ partial  
- ููุท ุฅุฐุง ุฎุทุฃ ูููููู ูุงุถุญ โ mistake

## โ๏ธ ุชุญุฐูุฑ ููู:
**ูุง ุชูู ุตุงุฑูุงู ุฌุฏุงู!** ุงูุทุงูุจ ููุณ ูุทููุจุงู ููู ุฃู ูุญูุธ ุงููุต. 
ุฅุฐุง ุฃุธูุฑ ูููุงู ููููููู ุงูุนูููุ ุฃุนุทู ุงูุฏุฑุฌุฉ.
"""
        return prompt
    
    def grade_answer(
        self,
        question_image_path: Path,
        answer_image_path: Path,
        max_score: int = 10,
        total_questions: int = None
    ) -> Dict:
        """
        Grade a student's answer using Gemini 3 Pro with DETERMINISTIC OCR-first approach.
        
        The key insight: We extract text FIRST using Google Cloud Vision OCR (deterministic),
        then send the extracted TEXT to Gemini for grading. This ensures the same image
        always produces the same grade.
        
        Args:
            question_image_path: Path to the question image
            answer_image_path: Path to the student's answer image
            max_score: Maximum score for this answer (default 10, can be 25 for midterms)
            total_questions: Total number of questions in midterm (for AI question detection)
            
        Returns:
            Dictionary with score, question_numbers, feedback_ar, and annotations
        """
        logger.info(f"Starting grading process (max_score={max_score}, total_questions={total_questions})")
        logger.info(f"Question: {question_image_path}")
        logger.info(f"Answer: {answer_image_path}")
        
        try:
            from utils.ocr_detector import extract_full_text
            
            # Check if question is a PDF (PDFs can't be OCR'd, but Gemini supports them directly)
            is_question_pdf = str(question_image_path).lower().endswith('.pdf')
            
            # STEP 1: Handle question file based on type
            if is_question_pdf:
                logger.info("Step 1: Question is PDF - will upload directly to Gemini")
                # Upload PDF to Gemini for this request
                question_file = self.client.files.upload(file=question_image_path)
                question_content = question_file  # Pass file object directly
                question_text = None  # No OCR text for PDF
            else:
                logger.info("Step 1: Question is image - extracting text via OCR...")
                question_text = extract_full_text(question_image_path)
                question_content = None  # No file object for images
                logger.info(f"Question text extracted: {len(question_text)} chars")
            
            # STEP 2: Extract text from student answer (always an image)
            logger.info("Step 2: Extracting student answer text via OCR...")
            answer_text = extract_full_text(answer_image_path)
            logger.info(f"Answer text extracted: {len(answer_text)} chars")
            
            # Log preview for debugging
            if question_text:
                logger.debug(f"Question preview: {question_text[:200]}...")
            logger.debug(f"Answer preview: {answer_text[:200]}...")
            
            # STEP 3: Build prompt and send to Gemini
            system_prompt = self._build_system_prompt(max_score=max_score, total_questions=total_questions)
            logger.info(f"Step 3: Sending to {GEMINI_MODEL} for grading...")
            
            # Build contents list with curriculum PDFs first
            contents = [system_prompt]
            
            # Add curriculum PDFs (reference answers)
            for category, file_obj in self.curriculum_files.items():
                contents.append(file_obj)
            
            # Add question content (either PDF file or OCR text)
            if is_question_pdf and question_content:
                contents.extend([
                    "ุงูููู ุงูุชุงูู ูู ููู ุงูุณุคุงู (PDF):",
                    question_content,
                ])
            else:
                contents.extend([
                    "ุงููุต ุงูุชุงูู ูู ูุต ุงูุณุคุงู (ุชู ุงุณุชุฎุฑุงุฌู ุจูุงุณุทุฉ OCR):",
                    f"```\n{question_text}\n```",
                ])
            
            # Add student answer (always OCR text)
            contents.extend([
                "ูุงูุขู ุฅููู ูุต ุฅุฌุงุจุฉ ุงูุทุงูุจ (ุชู ุงุณุชุฎุฑุงุฌู ุจูุงุณุทุฉ OCR):",
                f"```\n{answer_text}\n```",
                "ููุงุญุธุฉ ูููุฉ: ูุฐุง ุงููุต ุชู ุงุณุชุฎุฑุงุฌู ุขููุงู ูู ุตูุฑุฉ ุจุฎุท ุงููุฏ. ูุฏ ุชููู ููุงู ุฃุฎุทุงุก ุจุณูุทุฉ ูู ุงููุฑุงุกุฉ."
            ])
            
            response = self.client.models.generate_content(
                model=GEMINI_MODEL,
                contents=contents,
                config={
                    "temperature": 0.0,  # Zero temperature for deterministic grading
                    "response_mime_type": "application/json"
                }
            )
            
            # Parse response
            logger.info("Received response from Gemini")
            result_text = response.text
            
            # Parse JSON
            result = json.loads(result_text)
            
            # Detailed logging for debugging (server-side only, not visible to students)
            logger.info(f"Grading complete. Score: {result.get('score', 'N/A')}/{max_score}")
            logger.info(f"Detected question numbers: {result.get('question_numbers', [])}")
            logger.info(f"Annotations: {len(result.get('annotations', []))}")
            
            # Log each annotation's label for debugging
            for i, annot in enumerate(result.get('annotations', [])):
                label = annot.get('label', 'unknown')
                text_preview = annot.get('text', '')[:40]
                logger.info(f"  Annotation {i+1}: [{label}] '{text_preview}...'")
            
            # Log feedback summary
            feedback = result.get('feedback_ar', '')
            if feedback:
                logger.info(f"Feedback preview: {feedback[:100]}...")
            
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON response: {e}")
            logger.error(f"Response text: {result_text}")
            raise
        except Exception as e:
            logger.error(f"Grading error: {e}")
            raise

    def format_feedback_message(self, grading_result: Dict) -> str:
        """Format the grading result into a user-friendly message"""
        score = grading_result.get("score", 0)
        feedback = grading_result.get("feedback_ar", "")
        
        message = f"""๐ฏ ุงููุชูุฌุฉ: {score}/{MAX_SCORE}

๐ ุงูููุงุญุธุงุช:
{feedback}

โ ุงูุนูุงูุงุช ุนูู ุงูุตูุฑุฉ ุงููุฑููุฉ:
- โ ุฃุฎุถุฑ: ุตุญูุญ
- โ ุฃุญูุฑ: ุฎุทุฃ
- ! ุฃุตูุฑ: ุฌุฒุฆู
"""
        return message
