"""
Grading Session Module
======================
Manages grading sessions with Gemini context caching.
Creates a cached context (curriculum + exam) once per midterm,
then grades each student's ALL images in a single request.
"""

import json
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime, timezone, timedelta
from google import genai
from google.genai import types

import sys
sys.path.append(str(Path(__file__).parent.parent))
from config import GOOGLE_API_KEY, GEMINI_MODEL
from utils.logger import setup_logger

logger = setup_logger("grading_session")


# System prompt for holistic grading
HOLISTIC_GRADING_PROMPT = """ุฃูุช "ุงููุนูู" (Al-Muallim)ุ ููุตุญุญ ููุฒูุงุก ูุชููู ูุนุงุฏู.

## ูููุชู:
ุฃูุงูู ูุฑูุฉ ุงูุชุญุงู (PDF) ููุฌููุนุฉ ุตูุฑ ุชุญุชูู ุนูู ุฅุฌุงุจุงุช ุทุงูุจ ูุงุญุฏ.

---

## ๐ ุงูุฎุทูุฉ 1: ุชุญููู ูููู ุงูุงูุชุญุงู (ูู ููู PDF)

**ูุจู ุงูุจุฏุก ุจุงูุชุตุญูุญุ ุงูุฑุฃ ููู ุงูุงูุชุญุงู PDF ูุญุฏุฏ:**

ููู ุณุคุงู ุฑุฆูุณู:
1. **ุนุฏุฏ ุงูููุฑุงุช ุงูููู** (ูุซู: 12 ููุฑุฉ)
2. **ุนุฏุฏ ุงูููุฑุงุช ุงููุทููุจ ุงูุฅุฌุงุจุฉ ุนูููุง** (ูุซู: ุฃุฌุจ ุนู 10)
3. **ููุน ุงูุณุคุงู:**
   - `multiple_parts` = ููุฑุงุช ูุชุนุฏุฏุฉ (ุฃุฌุจ ุนู X ูู Y)
   - `choose_one` = ุงุฎุชุฑ ูุงุญุฏุงู ููุท (ูุดุงุท ุฃู ุชุฌุฑุจุฉ)
   - `compulsory` = ุณุคุงู ุฅุฌุจุงุฑู ูุงูู
4. **ุงุญุณุจ ุฏุฑุฌุฉ ูู ููุฑุฉ:**
   - ุฅุฐุง ูุงู `multiple_parts`: ุฏุฑุฌุฉ ุงูููุฑุฉ = 25 รท ุงูุนุฏุฏ ุงููุทููุจ
   - ุฅุฐุง ูุงู `choose_one`: ุฏุฑุฌุฉ ุงูุฎูุงุฑ ุงููุงุญุฏ = 25 ูุงููุฉ
   - ุฅุฐุง ูุงู `compulsory`: ุงูุฏุฑุฌุฉ ุงููุงููุฉ = 25

**โ๏ธ ูุงุนุฏุฉ ุฅุฌุจุงุฑูุฉ:**
- ุชุฌุงูู ุฃู ุฏุฑุฌุงุช ููุชูุจุฉ ูู ูุฑูุฉ ุงูุงูุชุญุงู!
- **ูู ุณุคุงู ุฑุฆูุณู = 25 ุฏุฑุฌุฉ ุจุงูุถุจุท**
- **ุงููุฌููุน ุงูููู = 100 ุฏุฑุฌุฉ (4 ุฃุณุฆูุฉ ร 25)**

---

## ๐ ุงูุฎุทูุฉ 2: ุชุญุฏูุฏ ุฑูู ุงูุณุคุงู ููู ุตูุฑุฉ

### ุงูุทุฑููุฉ ุงูุฃููู: ุงูุจุญุซ ุนู ุนูุงูุงุช ุตุฑูุญุฉ
ุงุจุญุซ ุนู ุนูุงูุงุช ูุซู: "ุณ1" ุฃู "ุฌ1" ุฃู "ุณ1/4" ุฃู "1-" ุฃู "4/"

### ุงูุทุฑููุฉ ุงูุซุงููุฉ: ูุทุงุจูุฉ ุงููุญุชูู (ุฅุฐุง ูู ุชูุฌุฏ ุนูุงูุงุช)
**ุฅุฐุง ูู ููุชุจ ุงูุทุงูุจ ุฑูู ุงูุณุคุงู ุจูุถูุญ:**
1. ุงูุฑุฃ ูุญุชูู ุงูุฅุฌุงุจุฉ ูู ุงูุตูุฑุฉ
2. ูุงุฑู ุงููุญุชูู ูุน ูู ุณุคุงู ูู ุงูุงูุชุญุงู
3. ุญุฏุฏ ุฃู ุณุคุงู ุชูุชูู ุฅููู ูุฐู ุงูุฅุฌุงุจุฉ ุจูุงุกู ุนูู ุงูููุถูุน

---

## ๐ ุงูุฎุทูุฉ 3: ุญุณุงุจ ุฏุฑุฌุฉ ูู ุตูุฑุฉ

**ุงุณุชุฎุฏู ุงูุฏุฑุฌุงุช ุงูุชู ุญุณุจุชูุง ูู ุงูุฎุทูุฉ 1:**

1. ุญุฏุฏ ุฑูู ุงูุณุคุงู ุงูุฐู ุชุฌูุจ ุนููู ุงูุตูุฑุฉ
2. ุนุฏ ุนุฏุฏ ุงูููุฑุงุช/ุงููุณุงุฆู ุงูุตุญูุญุฉ ูู ุงูุตูุฑุฉ
3. ุงุญุณุจ: **ุฏุฑุฌุฉ ุงูุตูุฑุฉ = ุนุฏุฏ ุงูุฅุฌุงุจุงุช ุงูุตุญูุญุฉ ร ุฏุฑุฌุฉ ุงูููุฑุฉ ุงููุงุญุฏุฉ**

**ุฃูุซูุฉ (ุงูุชุฑุงุถูุฉ - ุงุณุชุฎุฏู ุงูููู ุงูุชู ุญุณุจุชูุง):**
- ุฅุฐุง ูุงู ุณ1 ูุชุทูุจ 10 ููุฑุงุช: ุฏุฑุฌุฉ ุงูููุฑุฉ = 2.5
  - ุตูุฑุฉ ูููุง 3 ููุฑุงุช ุตุญูุญุฉ โ 3 ร 2.5 = 7.5
- ุฅุฐุง ูุงู ุณ4 ูุชุทูุจ 4 ูุณุงุฆู: ุฏุฑุฌุฉ ุงููุณุฃูุฉ = 6.25
  - ุตูุฑุฉ ูููุง ูุณุฃูุฉ ูุงุญุฏุฉ ุตุญูุญุฉ โ 1 ร 6.25 = 6.25
- ุฅุฐุง ูุงู ุณ3 "ุงุฎุชุฑ ูุงุญุฏุงู": ุฃู ูุดุงุท ุตุญูุญ = 25 ูุงููุฉ

---

## โ ููุงุนุฏ ุงูุชูููู:

### ุงูููู ุฃูู ูู ุงูุญูุธ:
โ ุฅุฐุง ุดุฑุญ ุงูุทุงูุจ ุงูููุฑุฉ ุจุดูู ุตุญูุญ ุจูููุงุชู ุงูุฎุงุตุฉ โ ุตุญูุญ!
โ ุฅุฐุง ุงุณุชุฎุฏู ูุตุทูุญุงุช ูุฎุชููุฉ ููู ุงููุนูู ุตุญูุญ โ ุตุญูุญ!
โ ููุท ุฅุฐุง ูุงู ุงูููููู ุฃู ุงูููุทู ุฎุงุทุฆ โ ุฎุทุฃ!

### ุชุฌููุน ุงูุฅุฌุงุจุงุช:
- ุงูุทุงูุจ ูุฏ ูุฌูุจ ุนูู ุฃุฌุฒุงุก ูู ุงูุณุคุงู ูู ุตูุฑ ูุฎุชููุฉ
- ุงุฌูุน ูู ุงูุฅุฌุงุจุงุช ููุณุคุงู ุงููุงุญุฏ ูู ุฌููุน ุงูุตูุฑ
- ูุง ุชุนุทู ุฏุฑุฌุฉ ูููุณ ุงูููุฑุฉ ูุฑุชูู

## ุงููููุฌ ุงูุฏุฑุงุณู:
ูููุงุช PDF ุงููุฑููุฉ ุชุญุชูู ุนูู ุงูููุงููู ุงูุตุญูุญุฉ.

## ูุชุทูุจุงุช ุงูุฅุฎุฑุงุฌ (JSON ููุท):

```json
{
  "exam_analysis": {
    "total_questions": 4,
    "total_points": 100,
    "questions": [
      {
        "number": <ุฑูู>,
        "type": "<ููุน>",
        "points": 25,
        "sub_count": <ุนุฏุฏ ุงูููุฑุงุช>,
        "required_count": <ุงูุนุฏุฏ ุงููุทููุจ>,
        "requirement": "<ุงููุทููุจ>"
      }
    ]
  },
  "student_grades": {
    "Q1": {
      "score": <ุฏุฑุฌุฉ ูู 0 ุฅูู 25>,
      "max_score": 25,
      "answered_parts": ["<ุงูุฃุฌุฒุงุก ุงูุชู ุฃุฌุงุจ ุนูููุง>"],
      "found_in_images": ["<ุฃุณูุงุก ุงูุตูุฑ>"],
      "feedback": "<ููุงุญุธุงุช>"
    },
    "Q2": { "score": <0-25>, "max_score": 25, ... },
    "Q3": { "score": <0-25>, "max_score": 25, ... },
    "Q4": { "score": <0-25>, "max_score": 25, ... }
  },
  "image_annotations": {
    "<ุงุณู ุงูุตูุฑุฉ>": {
      "question_number": <ุฑูู ุงูุณุคุงู>,
      "score": <ูุณุงููุฉ ูุฐู ุงูุตูุฑุฉ ูู ุฏุฑุฌุฉ ุงูุณุคุงู>,
      "max_score": 25,
      "annotations": [
        {
          "text": "<ุฃูู 15-20 ุญุฑู ูู ุฎุท ูุฏ ุงูุทุงูุจ ุจุงูุถุจุท>",
          "label": "correct|mistake|partial"
        }
      ]
    }
  },
  "total_score": <ุงููุฌููุน ูู 0 ุฅูู 100>,
  "total_max": 100,
  "overall_feedback": "<ููุงุญุธุงุช ุนุงูุฉ>"
}
```

### โ๏ธ ููุงุนุฏ ุญุณุงุจ ุฏุฑุฌุฉ ูู ุตูุฑุฉ (ููู ุฌุฏุงู!):

**score ูู image_annotations = ูุณุงููุฉ ูุฐู ุงูุตูุฑุฉ ููุท ูู ุฏุฑุฌุฉ ุงูุณุคุงู**

ูุซุงู: ุงูุณุคุงู ุงูุฃูู (ุณ1) = 25 ุฏุฑุฌุฉุ 10 ููุฑุงุช ูุทููุจุฉุ ูู ููุฑุฉ = 2.5 ุฏุฑุฌุฉ
- ุตูุฑุฉ ูููุง 1 ููุฑุฉ ุตุญูุญุฉ โ score: 2.5
- ุตูุฑุฉ ูููุง 3 ููุฑุงุช ุตุญูุญุฉ โ score: 7.5
- ุตูุฑุฉ ูููุง 7 ููุฑุงุช ุตุญูุญุฉ โ score: 17.5

ูุซุงู: ุงูุณุคุงู ุงูุซุงูู (ุณ2) = ุณุคุงู ุฅุฌุจุงุฑู ูุงูู = 25 ุฏุฑุฌุฉ
- ุตูุฑุฉ ูููุง ุฅุฌุงุจุฉ ุณ2 ูุงููุฉ ุตุญูุญุฉ โ score: 25

ูุซุงู: ุงูุณุคุงู ุงูุซุงูุซ (ุณ3) = ุงุฎุชุฑ ูุงุญุฏุงู = 25 ุฏุฑุฌุฉ
- ุตูุฑุฉ ูููุง ูุดุงุท ูุงุญุฏ ุตุญูุญ โ score: 25

### โ๏ธ ููุงุนุฏ ุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ:
- **text**: ูุฌุจ ุฃู ูููู **ุงูุญุฑูู ุงูุฃููู ุจุงูุถุจุท** ูู ุฎุท ูุฏ ุงูุทุงูุจ
  - โ ุตุญูุญ: "ููุง ูุง ูููู ูุงู" (ูุณุฎ ุญุฑูู ูู ุงูุตูุฑุฉ)
  - โ ุฎุทุฃ: "ุฅุฌุงุจุฉ ุนู ุณุจุจ ุนุฏู ุฅููุงููุฉ" (ููุฎุต ุฃู ูุตู)
- **ุงุณุชุฎุฏู ุฃูู 15-20 ุญุฑู ููุท** ูู ูู ุฅุฌุงุจุฉ ููุง ูุชุจูุง ุงูุทุงูุจ ุญุฑููุงู
- **label**: 
  - "correct" = ุฅุฌุงุจุฉ ุตุญูุญุฉ (โ)
  - "mistake" = ุฅุฌุงุจุฉ ุฎุงุทุฆุฉ (โ)
  - "partial" = ุฅุฌุงุจุฉ ุฌุฒุฆูุฉ (~)

**ุชุฐููุฑ: ูู ุณุคุงู = 25 ุฏุฑุฌุฉุ ุงููุฌููุน = 100 ุฏุฑุฌุฉ!**


ุฃุฑุฌุน JSON ููุท ุจุฏูู ุฃู ูุต ุฅุถุงูู.
"""


class GradingSession:
    """
    Manages a grading session with cached context.
    
    Usage:
        session = GradingSession.create(
            curriculum_pdfs=["kalamiat.pdf", "masael.pdf"],
            exam_pdf="exam.pdf",
            ttl_hours=24
        )
        result = session.grade_student(student_images)
        session.close()
    """
    
    def __init__(self, cache_name: str, client: genai.Client, exam_structure: dict = None):
        """Initialize with an existing cache"""
        self.cache_name = cache_name
        self.client = client
        self.exam_structure = exam_structure
        logger.info(f"GradingSession initialized with cache: {cache_name}")
    
    @classmethod
    def create(
        cls,
        curriculum_pdfs: List[Path],
        exam_pdf: Path,
        ttl_hours: int = 24,
        display_name: str = None
    ) -> 'GradingSession':
        """
        Create a new grading session with cached context.
        
        Args:
            curriculum_pdfs: List of paths to curriculum PDF files
            exam_pdf: Path to the exam PDF file
            ttl_hours: How long to keep the cache (default 24 hours)
            display_name: Optional name for the cache
            
        Returns:
            GradingSession instance
        """
        client = genai.Client(api_key=GOOGLE_API_KEY)
        
        logger.info("Creating grading session...")
        logger.info(f"Curriculum PDFs: {[p.name for p in curriculum_pdfs]}")
        logger.info(f"Exam PDF: {exam_pdf.name}")
        logger.info(f"TTL: {ttl_hours} hours")
        
        # Upload all files
        uploaded_files = []
        
        for pdf_path in curriculum_pdfs:
            logger.info(f"Uploading {pdf_path.name}...")
            file = client.files.upload(file=pdf_path)
            uploaded_files.append(file)
            logger.info(f"โ {pdf_path.name} uploaded")
        
        logger.info(f"Uploading {exam_pdf.name}...")
        exam_file = client.files.upload(file=exam_pdf)
        uploaded_files.append(exam_file)
        logger.info(f"โ {exam_pdf.name} uploaded")
        
        # Create cache with all context
        if display_name is None:
            display_name = f"midterm-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
        
        ttl_seconds = ttl_hours * 3600
        
        logger.info(f"Creating cached context: {display_name}")
        
        cache = client.caches.create(
            model=GEMINI_MODEL,
            config=types.CreateCachedContentConfig(
                display_name=display_name,
                system_instruction=HOLISTIC_GRADING_PROMPT,
                contents=uploaded_files,
                ttl=f"{ttl_seconds}s"
            )
        )
        
        logger.info(f"โ Cache created: {cache.name}")
        logger.info(f"  Expires: {cache.expire_time}")
        
        return cls(cache_name=cache.name, client=client)
    
    @classmethod
    def create_free_tier(
        cls,
        curriculum_pdfs: List[Path],
        exam_pdf: Path,
        display_name: str = None
    ) -> 'GradingSession':
        """
        Create a grading session WITHOUT context caching (for free tier API).
        
        Note: This uploads files each time but doesn't use caching.
        Works with Google AI Studio free API keys.
        
        Args:
            curriculum_pdfs: List of paths to curriculum PDF files
            exam_pdf: Path to the exam PDF file
            display_name: Optional name for logging
            
        Returns:
            GradingSession instance (with uploaded_files instead of cache)
        """
        client = genai.Client(api_key=GOOGLE_API_KEY)
        
        logger.info("Creating FREE TIER grading session (no caching)...")
        logger.info(f"Curriculum PDFs: {[p.name for p in curriculum_pdfs]}")
        logger.info(f"Exam PDF: {exam_pdf.name}")
        
        # Upload all files
        uploaded_files = []
        
        for pdf_path in curriculum_pdfs:
            logger.info(f"Uploading {pdf_path.name}...")
            file = client.files.upload(file=pdf_path)
            uploaded_files.append(file)
            logger.info(f"โ {pdf_path.name} uploaded")
        
        # Upload exam PDF
        logger.info(f"Uploading {exam_pdf.name}...")
        exam_file = client.files.upload(file=exam_pdf)
        uploaded_files.append(exam_file)
        logger.info(f"โ {exam_pdf.name} uploaded")
        
        logger.info(f"Free tier session ready with {len(uploaded_files)} files")
        
        # Create instance with files stored directly (no cache)
        instance = cls(cache_name=None, client=client)
        instance.uploaded_context_files = uploaded_files
        instance.is_free_tier = True
        return instance
    
    def grade_student(self, student_images: List[Path], output_dir: Path = None) -> Dict:
        """
        Grade a student's submission (all images at once) and annotate images.
        
        Args:
            student_images: List of paths to student answer images
            output_dir: Optional directory to save annotated images
            
        Returns:
            Dictionary with grades for each question, total, and annotated image paths
        """
        logger.info(f"Grading student with {len(student_images)} images")
        
        # Create output directory if needed
        if output_dir is None:
            output_dir = student_images[0].parent.parent / "graded_output"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Create a mapping of image name to path
        image_path_map = {img.name: img for img in student_images}
        
        # Upload student images
        uploaded_images = []
        image_names = []
        
        for img_path in student_images:
            logger.info(f"  Uploading: {img_path.name}")
            img_file = self.client.files.upload(file=img_path)
            uploaded_images.append(img_file)
            image_names.append(img_path.name)
        
        # Create grading request with image names for reference
        image_list = "\n".join([f"- {name}" for name in image_names])
        prompt = f"""ูู ุจุชุตุญูุญ ุฅุฌุงุจุงุช ูุฐุง ุงูุทุงูุจ.

ุงูุตูุฑ ุงููุฑููุฉ (ุจุงูุชุฑุชูุจ):
{image_list}

ุญูู ุฌููุน ุงูุตูุฑ ูุฃุนุทูู ุฏุฑุฌุฉ ูู ุณุคุงู ูุงููุฌููุน ูุน ุงูุชุนูููุงุช ุงูุชูุถูุญูุฉ ููู ุตูุฑุฉ.
"""
        
        # Build contents list
        contents = uploaded_images + [prompt]
        
        logger.info("Sending grading request to Gemini...")
        
        # Check if we're in free tier mode (no cache)
        if getattr(self, 'is_free_tier', False):
            # Free tier: include context files directly in request
            all_contents = self.uploaded_context_files + contents
            response = self.client.models.generate_content(
                model=GEMINI_MODEL,
                contents=all_contents,
                config=types.GenerateContentConfig(
                    system_instruction=HOLISTIC_GRADING_PROMPT
                )
            )
        else:
            # Paid tier: use cached context
            response = self.client.models.generate_content(
                model=GEMINI_MODEL,
                contents=contents,
                config=types.GenerateContentConfig(
                    cached_content=self.cache_name
                )
            )
        
        logger.info(f"Response received. Usage: {response.usage_metadata}")
        
        # Parse JSON response
        response_text = response.text.strip()
        
        # Extract JSON from markdown code blocks if present
        if "```json" in response_text:
            start = response_text.find("```json") + 7
            end = response_text.find("```", start)
            response_text = response_text[start:end].strip()
        elif "```" in response_text:
            start = response_text.find("```") + 3
            end = response_text.find("```", start)
            response_text = response_text[start:end].strip()
        
        try:
            result = json.loads(response_text)
            self._log_results(result)
            
            # Annotate images if annotations are provided
            if "image_annotations" in result:
                annotated_paths = self._annotate_images(
                    result["image_annotations"],
                    image_path_map,
                    output_dir,
                    result.get("total_score", 0),
                    result.get("total_max", 100)
                )
                result["annotated_images"] = annotated_paths
            
            return result
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse grading response: {e}")
            logger.error(f"Raw response: {response_text[:1000]}")
            return {"error": str(e), "raw_response": response_text}
    
    def _annotate_images(
        self, 
        image_annotations: Dict, 
        image_path_map: Dict[str, Path],
        output_dir: Path,
        total_score: int,
        total_max: int
    ) -> Dict[str, Path]:
        """
        Annotate student images with checkmarks/X marks based on grading results.
        
        Args:
            image_annotations: Dict of {image_name: {annotations: [...]}}
            image_path_map: Dict of {image_name: Path}
            output_dir: Directory to save annotated images
            total_score: Student's total score
            total_max: Maximum possible score
            
        Returns:
            Dict of {image_name: annotated_image_path}
        """
        from grading.annotator import draw_annotations_with_ocr
        
        logger.info(f"Annotating {len(image_annotations)} images...")
        annotated_paths = {}
        running_total = 0
        
        for img_name, img_data in image_annotations.items():
            if img_name not in image_path_map:
                logger.warning(f"Image not found: {img_name}")
                continue
            
            img_path = image_path_map[img_name]
            annotations = img_data.get("annotations", [])
            score = img_data.get("score", 0)
            max_score = img_data.get("max_score", 25)
            running_total += score
            
            output_path = output_dir / f"graded_{img_name}"
            
            try:
                annotated_path = draw_annotations_with_ocr(
                    image_path=img_path,
                    text_annotations=annotations,
                    score=score,
                    max_score=max_score,
                    running_total=(running_total, total_max),
                    output_path=output_path
                )
                annotated_paths[img_name] = str(annotated_path)
                logger.info(f"  โ Annotated: {img_name}")
            except Exception as e:
                logger.error(f"  โ Failed to annotate {img_name}: {e}")
        
        logger.info(f"Annotation complete: {len(annotated_paths)} images annotated")
        return annotated_paths
    
    def _log_results(self, result: Dict):
        """Log grading results"""
        if "student_grades" in result:
            logger.info("=" * 50)
            logger.info("GRADING RESULTS")
            logger.info("=" * 50)
            
            for q_key, q_data in result.get("student_grades", {}).items():
                score = q_data.get("score", 0)
                max_score = q_data.get("max_score", 25)
                feedback = q_data.get("feedback", "")[:50]
                logger.info(f"  {q_key}: {score}/{max_score} - {feedback}...")
            
            total = result.get("total_score", 0)
            total_max = result.get("total_max", 100)
            logger.info(f"  TOTAL: {total}/{total_max}")
    
    def close(self):
        """Delete the cache to free resources"""
        try:
            self.client.caches.delete(name=self.cache_name)
            logger.info(f"Cache deleted: {self.cache_name}")
        except Exception as e:
            logger.warning(f"Failed to delete cache: {e}")
    
    @classmethod
    def list_active_sessions(cls) -> List[Dict]:
        """List all active grading sessions"""
        client = genai.Client(api_key=GOOGLE_API_KEY)
        sessions = []
        for cache in client.caches.list():
            sessions.append({
                "name": cache.name,
                "display_name": cache.display_name,
                "expire_time": cache.expire_time
            })
        return sessions


# Convenience function for quick grading
def grade_student_submission(
    curriculum_pdfs: List[Path],
    exam_pdf: Path,
    student_images: List[Path],
    ttl_hours: int = 24
) -> Dict:
    """
    One-shot function to grade a student's complete submission.
    
    Creates a session, grades the student, and returns results.
    For grading multiple students, use GradingSession directly to reuse the cache.
    """
    session = GradingSession.create(
        curriculum_pdfs=curriculum_pdfs,
        exam_pdf=exam_pdf,
        ttl_hours=ttl_hours
    )
    
    try:
        result = session.grade_student(student_images)
        return result
    finally:
        # Don't close session in case of reuse
        pass
